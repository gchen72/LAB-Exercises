{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "452f3962",
   "metadata": {},
   "source": [
    "# Post LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4da021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "\n",
    "\n",
    "PATH = Service(\"/Users/gindychen/Desktop/chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service = PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a385d745",
   "metadata": {},
   "source": [
    "_VIDEO #3_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd5501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "website= \"https://techwithtim.net\" #set variable website to the website url\n",
    "driver.get(website) #get html of website\n",
    "\n",
    "link = driver.find_element(By.LINK_TEXT,\"Python Programming\") # find the link text and set to link\n",
    "link.click() # click the link text\n",
    "\n",
    "try: \n",
    "    element = WebDriverWait(driver,10).until(\n",
    "    EC.presence_of_element_located((By.LINK_TEXT, \"Beginner Python Tutorials\"))\n",
    "    ) # set element to find element by link text, wait at least 10 seconds and see if the element appears and then continue\n",
    "    element.click() #click the link set to element\n",
    "    start = WebDriverWait(driver,10).until(   \n",
    "    EC.presence_of_element_located((By.ID, \"sow-button-19310003\"))\n",
    "    )# set start to find element by link text, wait at least 10 seconds and see if the element appears and then continue\n",
    "    start.click() #click the link set to start\n",
    "    driver.back() # goes back one page\n",
    "    driver.back()\n",
    "    driver.back() \n",
    "    driver.forward() # goes to the next page\n",
    "    driver.forward()\n",
    "except: \n",
    "    driver.quit() # exit out of the browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990570b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4517a1d4",
   "metadata": {},
   "source": [
    "_CAT IMAGE LINK_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37c3ede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_three = \"https://www.wikipedia.org/\"\n",
    "driver.get(website_three)\n",
    "#Use selenium to search https://www.wikipedia.org/ for the word “cat” and then scrape the url\n",
    "#links to all the images on the page. Store those in a csv file. (Bonus 1pt can you add the \n",
    "#https:// part of the url to the links so they are clickable)\n",
    "\n",
    "search = driver.find_element(By.NAME, \"search\")\n",
    "search.clear() # clear any text in the search\n",
    "search.send_keys(\"cat\") \n",
    "search.send_keys(Keys.RETURN)\n",
    "\n",
    "\n",
    "csv_file = open(\"cat_img_link.csv\", \"w\", newline=\"\", encoding = \"utf-8\")\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\"Img Link\"]) # column names \n",
    "\n",
    "    \n",
    "img = driver.find_elements(By.TAG_NAME,\"img\")\n",
    "for i in img:\n",
    "    link = i.get_attribute(\"src\")\n",
    "    csv_writer.writerow([link])\n",
    "\n",
    "csv_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7e04f2",
   "metadata": {},
   "source": [
    "_BONUS_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f58887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_four = \"https://www.wikipedia.org/\"\n",
    "driver.get(website_four)\n",
    "#Use selenium to search https://www.wikipedia.org/ for the word “cat” and then scrape the url\n",
    "#links to all the images on the page. Store those in a csv file. (Bonus 1pt can you add the \n",
    "#https:// part of the url to the links so they are clickable)\n",
    "\n",
    "search = driver.find_element(By.NAME, \"search\")\n",
    "search.clear() # clear any text in the search\n",
    "search.send_keys(\"dogs\")  # searched up dogs\n",
    "search.send_keys(Keys.RETURN)\n",
    "\n",
    "\n",
    "csv_file = open(\"dog_sections.csv\", \"w\", newline=\"\", encoding = \"utf-8\") #creating a csv\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\"Section Headers\"]) # column name\n",
    "\n",
    "section= driver.find_elements(By.CLASS_NAME,\"mw-headline\")\n",
    "for i in section:      #lope throught the list\n",
    "    name = i.text   #find the section header\n",
    "    csv_writer.writerow([name]) \n",
    "\n",
    "csv_file.close()   #close file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578cde1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
